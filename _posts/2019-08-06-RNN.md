---
layout: post
title: "Recurrent Neural Network와 LSTM"
date: 2019-08-06 00:00:00
excerpt: "이 글은 CS231n 강의를 정리한 것입니다. "  
tags:
- ML
- DEEPLearning
categories:
- 공부
---
## Table of Contents
1. [Recurrent Neural Network](#rnn)
2. [Backpropagation](#back)
3. [LSTM](#lstm)

### 1. Recurrent Neural Network<a name="rnn"></a>
RNN 은 Neural Network의 한 종류로, 모델의 **flexibility**를 증가시키기 위해 고안되었습니다.  
일반적인 Neural Network의 경우, 입력과 출력이 고정(one-to-one) 되어있다는 단점이 있는데, 이를 해결하고자 RNN을 도입하였습니다.  
  
RNN은 **core cell**이라 부르는 노드를 중심으로 구성되어 있는데, 이 노드 덕분에 네트워크의 입력과 출력이 가변적인 길이를 가지게 될 수 있습니다. 이러한 특성을 가진 RNN은 문자 등을 처리하는 모델에 유용하게 쓰이고 있습니다.  
  
RNN 모델은 매 *time step*마다 hidden state인 를 갱신해나가며 입력 시퀀스를 처리해 나갑니다.  
여기서 hidden state는,  
$$ h_{t} = F_{w}(h_{t-1},x_{t}) $$
로, 이전 state와 입력의 함수로 구성됩니다.  

#### Vanila RNN
Activation 함수로 tanh함수를 이용하고,  출력인 y는 $$ h_{t} $$와 weight matrix인 W의 곱으로 구성됩니다.  

$$ h_{t} = tanh(W_{hh}h_{t-1}+W_{xh}x_{t}) $$  
$$ y_{t} = W_{hy}h_{t} $$
이고, weight matrix인 W는 모든 t에 대해 동일하게 적용됩니다.

#### Example : character-level-model

### 2. Backpropagation<a name="back"></a>

### 3. LSTM(Long Short Term Memory)<a name="lstm"></a>
