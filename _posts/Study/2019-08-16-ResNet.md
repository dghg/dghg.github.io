---
layout: post
title: "ResNet(2015) (1)"
date: 2019-08-13 00:00:00
excerpt: "ResNet 설명 및 Tensorflow  "  
tags:
- Study
categories:
- 공부
---
## Table of Contents 
1. [Introduction](#intro)
2. [Deep Residual Learning](#res)
3. [Network Architecture](#network)
4. [Experiment](#exp)
5. [요약](#sum)  
  
   
   
### 1. Introduction<a name="intro"></a>
2012년의 Alexnet 이후로 Image Classification 분야의 대세는 딥러닝이 되었습니다. 현재 State-of-the-art는 모두 VGGNet, GoogleNet같은 "Very Deep"한 모델들입니다.   이러한 모델들의 특징은 모두 Convolution을 여러개 쌓아 "Depth" 가 깊은 모델들이라 할 수 있습니다. 그럼 여기서 한 가지 의문을 제기할 수 있습니다.  
바로 *Depth가 커지면 무조건 좋을까?*   
당연히 답은 아닙니다. 다음에서 보듯이 깊게 쌓은 Layer가 마냥 좋은 performance를 보여주진 않습니다.
![Graph1](https://github.com/dghg/dghg.github.io/raw/master/_posts/img/1-res.PNG)  
  
그림에서 보다시피 56-layer가 20-layer에 비해 에러가 상대적으로 높은 것을 볼 수 있습니다. 나머지 36개의 Layer를 identity 로 구성해도 20-layer와 에러가 비슷해야 하는데, 그렇지 않다는 것입니다.  
이런 현상이 발생하는 원인은 바로 모델이 Deep해질수록 gradient vanishing/exploding 문제가 발생하게 되는데, 이런 문제를 바로 **degradation**이라 합니다.  
ResNet은 **degradation**문제를 "Residual Block"이라 부르는 shortcut-connection을 이용해 해결 하였습니다.  
  
#### Residual Mapping
![Block](https://github.com/dghg/dghg.github.io/raw/master/_posts/img/2-res.PNG)  
$$ H(x) $$를 레이어의 출력이라 하면, $$ H(x) $$ 와 $$ x $$의 차이인 $$F(x) = H(x) - x $$ 를 학습하는 것입니다. 논문에서는 $$ H(x) $$를 직접 학습하는 것 보다 $$ F(x) + x $$를 학습하는게 쉬울것이라고 가정합니다. (We **hypothesize** that it is easier to optimize the residual mapping than to optimize the original)  
  
이러한 구조를 사용한 ResNet은 , 2015 ILSVRC에서 COCO, Imagenet 상관없이 모두 1st places를 차지했습니다. 이를 통해 residual learning은 특정한 모델에만 적용되는게 아니고 다른 분야에도 모두 적용할 수 있을 것이라는 예측을 할 수 있습니다.  
  
  
### 2. Deep Residual Learning <a name="res"></a>  
introduction에서 설명했듯이, 추가된 Layer들이 identity-mapping 이라면 Deep한 모델(identity가 추가된 모델)이 기존의 shallow 모델보다 에러가 낮아야하는데 그렇지 못합니다.   
이러한 이유는 바로 $$ H(x) $$라는 Nonlinear Layer가 학습이 잘 안된다는 것입니다. 따라서 우리는 Residual fuctnion $$ F(x) + x$$를 학습하게 됩니다.  
실제로, $$H(x)$$가 identity-mapping 이 Optimal인 레이어라면 학습 진행 과정에서 $$F(x) $$는 0이 될 것입니다. 하지만 real cases 들에서는 identity가 Optimal 한 경우는 없지만, reformulation 과정이 학습에 도움이 됩니다.  
  
#### Identity Mapping by Shortcuts
Residual Block을 다음과 같이 정의할 수 있습니다.  
$$ y = F(x,{W_{i}})+x $$  
만약에 F가 두개의 layer로 이루어 졌다면,  
$$ y = W_{2}\sigma(W_{1}x) $$로 나타낼 수 있습니다.  또한 연산 $$ F + x $$ 는 element-wise 연산으로, dimension이 같아야 진행할 수 있습니다.  
만약 F와 x의 dimension이 다르다면, Linear Projection $$ W_{s} $$ 을 이용하여 다음과 같이 나타낼 수 있습니다.  
$$ y = F(x,{W_{i}})+W_{s}x $$  
여기서 F는 위의 예시처럼 2-Layer가 될 수도 있고, 여러 Layer를 나타낼 수도 있지만, 만약에 1-Layer라면 $$ y = W_{1}x + x $$ 로 Linear한 형태가 되어 의미가 없어집니다.  

  
### 3. Network Architecture<a name="network"></a> 
논문에서는 다양한 plain/residual 네트워크를 이용하여 실험을 진행하였습니다.  
![Network](https://github.com/dghg/dghg.github.io/raw/master/_posts/img/3-res.PNG)  
#### 1) Plain Network
3 by 3 필터를 사용한 VGGnet의 구조와 유사하지만, 계산량을 줄이기 위해서 3개의 FC Layer를 사용한 VGGNet과 달리 global average pooling과 1개의 1000-way FC Layer를 사용하였습니다. 이를 통해 VGG-19에 비해 18%라는 계산량으로 모델을 구성할 수 있게 되었습니다.    
#### 2) Residual Network
1의 Plain Network를 기본으로, 중간에 shortcut connection을 삽입하였습니다. 위에서 dotted-line으로 된 shortcut의 경우는 Linear Projection 또는 Zero-padding을 이용해 dimension을 맞춰준 부분입니다.

### 4. Experiment  <a name="exp"></a> 
  
#### 1. ImageNet Classification
![Experiment1](https://github.com/dghg/dghg.github.io/raw/master/_posts/img/4-res.PNG) 
![Experiment1](https://github.com/dghg/dghg.github.io/raw/master/_posts/img/5-res.PNG)
##### Plain Network
비슷한 형태의 18-Layer와 34-layer 를 가지고 진행하였는데, 34-layer가 18-layer보다 에러율이 높은 degradation 문제가 발견됩니다. 
##### Residual Network
Plain 모델과 같은 구조를 가진 18-layer 와 34-layer ResNet을 가지고 진행하였습니다. shortcut에서 dimension 조정이 필요할 경우 **zero-padding**을 사용하였습니다. ResNet을 사용할 경우 plain과 반대로 모델의 depth가 깊어질 수록 error가 상당히 낮아진다는 것입니다. 이것은 바로 ResNet이 degradation 문제를 잘 해결할 수 있다는 것을 보여줍니다.  
또한, 같은 depth의 모델일지라도 ResNet이 error가 낮은 것을 볼 수 있습니다.  
마지막으로, 18-layer의 plain/residual network를 보면 비슷한 정확도를 가지지만, ResNet을 적용한 쪽이 더욱 빠른 속도로 수렴함을 볼 수 있습니다.  
  
##### Identity vs. Projection Shortcut
여기서는 projection의 경우 세 가지 옵션에 대해 실험을 진행하였습니다. (A) zero-padding shortcut 만 사용 (B) 일부 shortcut에만 projection $$W_{s}$ 사용 (C) 모든 shortcut에 projection 사용  
  
3개의 모델의 에러율은 다음과 같습니다. 어떤 옵션을 선택하던 에러는 비슷하게 나타납니다. 
![Experiment1](https://github.com/dghg/dghg.github.io/raw/master/_posts/img/6-res.PNG)

##### Deeper Bottleneck Architecture.
ResNet-50부터는 *bottleneck design*을 사용하였습니다. 여기서는  1\*1, 3\*3, 1\*1 Convolution 을 이용하여 3-layer를 쌓았습니다.
![Experiment1](https://github.com/dghg/dghg.github.io/raw/master/_posts/img/8-res.PNG)
이런 구조를 이용해서 ResNet-152은 *ILSVRC 2015*에서 1st place를 차지하게 됩니다.
![Experiment1](https://github.com/dghg/dghg.github.io/raw/master/_posts/img/7-res.PNG)


### 5. 요약<a name="sum"></a> 
1. Depth가 커질수록 모델의 performance가 떨어지는 **Degradation** 문제가 발생한다.  2. 이것을 완화하기 위해 Residual Learning을 사용하였다.  
3. $$H(x)$$ 대신 $$F(x) + x$$를 사용함으로써 레이어가 최소한($$F(x)=0$$) identity-layer가 됨을 보장하여 성능이 저하되는 것을 막아준다.

### References
1. [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)